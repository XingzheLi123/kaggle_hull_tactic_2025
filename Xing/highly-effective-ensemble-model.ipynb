{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75d8de10",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-31T11:16:23.258310Z",
     "iopub.status.busy": "2025-10-31T11:16:23.257983Z",
     "iopub.status.idle": "2025-10-31T11:16:44.719339Z",
     "shell.execute_reply": "2025-10-31T11:16:44.718450Z"
    },
    "papermill": {
     "duration": 21.466574,
     "end_time": "2025-10-31T11:16:44.721007",
     "exception": false,
     "start_time": "2025-10-31T11:16:23.254433",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Initializing and training the final model... ---\n",
      "Performing feature selection...\n",
      "Training the final model on the lean feature set...\n",
      "Model training complete.\n",
      "--- Initialization complete. Ready for inference. ---\n",
      "Evaluating on test set...\n",
      "0.498 0.004799884985123216\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from collections import deque\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# --- PART 1: INITIALIZATION AND TRAINING (Unchanged) ---\n",
    "print(\"--- Initializing and training the final model... ---\")\n",
    "\n",
    "# 1.1: Load and Prepare Training Data\n",
    "full_train_df = pd.read_csv('../train.csv')\n",
    "\n",
    "# 1.2: Initial Feature Engineering\n",
    "cutoff_date_id = 3283\n",
    "df_subset = full_train_df[full_train_df['date_id'] >= cutoff_date_id].copy()\n",
    "df_subset = df_subset.sort_values('date_id').ffill().bfill()\n",
    "\n",
    "top_features_for_rolling = ['M4', 'V13', 'P8', 'S5']\n",
    "for feature in top_features_for_rolling:\n",
    "    if feature in df_subset.columns:\n",
    "        df_subset[f'{feature}_roll_mean_20'] = df_subset[feature].rolling(window=20).mean()\n",
    "\n",
    "if 'S5' in df_subset.columns and 'V13' in df_subset.columns:\n",
    "    df_subset['S5_x_V13'] = df_subset['S5'] * df_subset['V13']\n",
    "\n",
    "df_train = df_subset.iloc[:-1000]\n",
    "df_test = df_subset.iloc[-1000:]\n",
    "\n",
    "df_featured = df_train.dropna()\n",
    "\n",
    "# 1.3: Feature Selection\n",
    "print(\"Performing feature selection...\")\n",
    "X_temp = df_featured.drop(columns=['date_id', 'market_forward_excess_returns', 'forward_returns', 'risk_free_rate'], errors='ignore')\n",
    "y_temp = df_featured['market_forward_excess_returns']\n",
    "\n",
    "feature_selector_model = RandomForestRegressor(n_estimators=100, max_depth=10, min_samples_leaf=10, random_state=42, n_jobs=-1)\n",
    "feature_selector_model.fit(X_temp, y_temp)\n",
    "\n",
    "importances = feature_selector_model.feature_importances_\n",
    "feature_importance_df = pd.DataFrame({'feature': X_temp.columns, 'importance': importances})\n",
    "top_30_features = feature_importance_df.sort_values('importance', ascending=False).head(30)['feature'].tolist()\n",
    "\n",
    "df_lean = df_featured[['date_id', 'market_forward_excess_returns', 'forward_returns', 'risk_free_rate'] + top_30_features]\n",
    "\n",
    "# 1.4: Train the Final Model\n",
    "print(\"Training the final model on the lean feature set...\")\n",
    "X_final_train = df_lean[top_30_features]\n",
    "y_final_train = df_lean['market_forward_excess_returns']\n",
    "\n",
    "final_model = RandomForestRegressor(n_estimators=100, max_depth=10, min_samples_leaf=10, random_state=42, n_jobs=-1)\n",
    "final_model.fit(X_final_train, y_final_train)\n",
    "print(\"Model training complete.\")\n",
    "\n",
    "print(\"--- Initialization complete. Ready for inference. ---\")\n",
    "\n",
    "X_test = df_test[top_30_features]\n",
    "y_test = df_test[['market_forward_excess_returns', 'forward_returns', 'risk_free_rate']]\n",
    "\n",
    "y_pred = final_model.predict(X_test)\n",
    "\n",
    "print(\"Evaluating on test set...\")\n",
    "print(hit_rate(y_test['market_forward_excess_returns'], y_pred), pearson_corr(y_test['market_forward_excess_returns'], y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e1c7339",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(solution: pd.DataFrame, submission) -> float:\n",
    "    \"\"\"\n",
    "    Calculates a custom evaluation metric (volatility-adjusted Sharpe ratio).\n",
    "\n",
    "    This metric penalizes strategies that take on significantly more volatility\n",
    "    than the underlying market.\n",
    "\n",
    "    Returns:\n",
    "        float: The calculated adjusted Sharpe ratio.\n",
    "    \"\"\"\n",
    "\n",
    "  \n",
    "    solution = solution.copy()\n",
    "    solution.loc[:, 'position'] = submission\n",
    "\n",
    "    solution['strategy_returns'] = solution['risk_free_rate'] * (1 - solution['position']) + solution['position'] * solution['forward_returns']\n",
    "\n",
    "    # Calculate strategy's Sharpe ratio\n",
    "    strategy_excess_returns = solution['strategy_returns'] - solution['risk_free_rate']\n",
    "    strategy_excess_cumulative = (1 + strategy_excess_returns).prod()\n",
    "    strategy_mean_excess_return = (strategy_excess_cumulative) ** (1 / len(solution)) - 1\n",
    "    strategy_std = solution['strategy_returns'].std()\n",
    "    trading_days_per_yr = 252\n",
    "    sharpe = strategy_mean_excess_return / strategy_std * np.sqrt(trading_days_per_yr)\n",
    "    strategy_volatility = float(strategy_std * np.sqrt(trading_days_per_yr) * 100)\n",
    "\n",
    "    # Calculate market return and volatility\n",
    "    market_excess_returns = solution['forward_returns'] - solution['risk_free_rate']\n",
    "    market_excess_cumulative = (1 + market_excess_returns).prod()\n",
    "    market_mean_excess_return = (market_excess_cumulative) ** (1 / len(solution)) - 1\n",
    "    market_std = solution['forward_returns'].std()\n",
    "\n",
    "\n",
    "    market_volatility = float(market_std * np.sqrt(trading_days_per_yr) * 100)\n",
    "\n",
    "\n",
    "    # Calculate the volatility penalty\n",
    "    excess_vol = max(0, strategy_volatility / market_volatility - 1.2) if market_volatility > 0 else 0\n",
    "    vol_penalty = 1 + excess_vol\n",
    "\n",
    "    # Calculate the return penalty\n",
    "    return_gap = max(\n",
    "        0,\n",
    "        (market_mean_excess_return - strategy_mean_excess_return) * 100 * trading_days_per_yr,\n",
    "    )\n",
    "    return_penalty = 1 + (return_gap**2) / 100\n",
    "\n",
    "    # Adjust the Sharpe ratio by the volatility and return penalty\n",
    "    adjusted_sharpe = sharpe / (vol_penalty * return_penalty)\n",
    "    return min(float(adjusted_sharpe), 1_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8616ed02",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_position = np.clip(y_pred*200, 0.0, 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc8748ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.01017112537707895"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_value = score(y_test, y_pred)\n",
    "score_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebeca3ec",
   "metadata": {
    "papermill": {
     "duration": 0.001588,
     "end_time": "2025-10-31T11:16:44.873133",
     "exception": false,
     "start_time": "2025-10-31T11:16:44.871545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def hit_rate(y_true, y_pred, *, dropna: bool = True, margin: float = 0.0, count_ties: bool = False) -> float:\n",
    "    \"\"\"\n",
    "    Sign accuracy (hit rate): fraction of times sign(y_pred) == sign(y_true).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true, y_pred : array-like\n",
    "        Equal-length sequences of numbers.\n",
    "    dropna : bool, default True\n",
    "        If True, drop any pair with NaN in either array.\n",
    "        If False and NaNs are present, returns np.nan.\n",
    "    margin : float, default 0.0\n",
    "        Treat predictions with |y_pred| <= margin as 0 (neutral band).\n",
    "    count_ties : bool, default False\n",
    "        If False, exclude any pair where sign is 0 on either side.\n",
    "        If True, include pairs with sign==0 and count them as correct\n",
    "        only when both are 0.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    hit : float\n",
    "        Proportion in [0,1], or np.nan if no eligible pairs.\n",
    "    \"\"\"\n",
    "    a = np.asarray(y_true, dtype=float).flatten()\n",
    "    b = np.asarray(y_pred, dtype=float).flatten()\n",
    "\n",
    "    if a.shape != b.shape:\n",
    "        raise ValueError(\"y_true and y_pred must have the same shape\")\n",
    "\n",
    "    mask = np.isfinite(a) & np.isfinite(b)\n",
    "    if not dropna and not mask.all():\n",
    "        return np.nan\n",
    "    a = a[mask]\n",
    "    b = b[mask]\n",
    "\n",
    "    # Apply neutral band to predictions\n",
    "    if margin > 0:\n",
    "        b = b.copy()\n",
    "        b[np.abs(b) <= margin] = 0.0\n",
    "\n",
    "    s_true = np.sign(a)\n",
    "    s_pred = np.sign(b)\n",
    "\n",
    "    if count_ties:\n",
    "        eligible = np.ones_like(s_true, dtype=bool)\n",
    "    else:\n",
    "        eligible = (s_true != 0) & (s_pred != 0)\n",
    "\n",
    "    if not np.any(eligible):\n",
    "        return np.nan\n",
    "\n",
    "    hits = (s_true[eligible] == s_pred[eligible]).mean()\n",
    "    return float(hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ce05b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_corr(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Pearson correlation coefficient between y_true and y_pred.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true, y_pred : array-like\n",
    "        Equal-length sequences of numbers.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    corr : float\n",
    "        Pearson correlation coefficient in [-1,1], or np.nan if undefined.\n",
    "    \"\"\"\n",
    "    a = np.asarray(y_true, dtype=float).flatten()\n",
    "    b = np.asarray(y_pred, dtype=float).flatten()\n",
    "\n",
    "    if a.shape != b.shape:\n",
    "        raise ValueError(\"y_true and y_pred must have the same shape\")\n",
    "\n",
    "    mask = np.isfinite(a) & np.isfinite(b)\n",
    "    a = a[mask]\n",
    "    b = b[mask]\n",
    "\n",
    "    if len(a) == 0:\n",
    "        return np.nan\n",
    "\n",
    "    corr, _ = pearsonr(a, b)\n",
    "    return float(corr)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 13750964,
     "sourceId": 111543,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 26.728173,
   "end_time": "2025-10-31T11:16:45.598058",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-31T11:16:18.869885",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
