{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "85c053f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import pearsonr\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from arch.univariate import ConstantMean, GARCH, StudentsT, Normal\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # nuke all warnings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "6174179e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('X_train_enriched.csv')\n",
    "y_train = pd.read_csv('y_train.csv')['market_forward_excess_returns']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c8833249",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features_train = X_train[-252:]\n",
    "X_train = X_train[:-252]\n",
    "y_features_train = y_train[-252:]\n",
    "y_train = y_train[:-252]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d7b9de89",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cleaned = X_train.ffill().fillna(0)\n",
    "X_features_train_cleaned = X_features_train.ffill().fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "481c7b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_features = ['D1',\n",
    " 'D2',\n",
    " 'D3',\n",
    " 'D4',\n",
    " 'D5',\n",
    " 'D6',\n",
    " 'D7',\n",
    " 'D8',\n",
    " 'D9',\n",
    " 'E1',\n",
    " 'E10',\n",
    " 'E11',\n",
    " 'E12',\n",
    " 'E13',\n",
    " 'E14',\n",
    " 'E15',\n",
    " 'E16',\n",
    " 'E17',\n",
    " 'E18',\n",
    " 'E19',\n",
    " 'E2',\n",
    " 'E20',\n",
    " 'E3',\n",
    " 'E4',\n",
    " 'E5',\n",
    " 'E6',\n",
    " 'E8',\n",
    " 'E9',\n",
    " 'I1',\n",
    " 'I2',\n",
    " 'I3',\n",
    " 'I4',\n",
    " 'I5',\n",
    " 'I6',\n",
    " 'I7',\n",
    " 'I8',\n",
    " 'I9',\n",
    " 'M10',\n",
    " 'M11',\n",
    " 'M12',\n",
    " 'M15',\n",
    " 'M16',\n",
    " 'M17',\n",
    " 'M18',\n",
    " 'M2',\n",
    " 'M3',\n",
    " 'M4',\n",
    " 'M5',\n",
    " 'M7',\n",
    " 'M8',\n",
    " 'M9',\n",
    " 'P1',\n",
    " 'P10',\n",
    " 'P11',\n",
    " 'P12',\n",
    " 'P13',\n",
    " 'P2',\n",
    " 'P3',\n",
    " 'P4',\n",
    " 'P5',\n",
    " 'P6',\n",
    " 'P7',\n",
    " 'P8',\n",
    " 'P9',\n",
    " 'S1',\n",
    " 'S10',\n",
    " 'S11',\n",
    " 'S12',\n",
    " 'S2',\n",
    " 'S4',\n",
    " 'S5',\n",
    " 'S6',\n",
    " 'S7',\n",
    " 'S8',\n",
    " 'S9',\n",
    " 'V1',\n",
    " 'V11',\n",
    " 'V12',\n",
    " 'V13',\n",
    " 'V2',\n",
    " 'V3',\n",
    " 'V4',\n",
    " 'V5',\n",
    " 'V6',\n",
    " 'V7',\n",
    " 'V8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8c05f260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(X_tr, y_tr, X_va, y_va, *, k=30, top_corr=60,\n",
    "                     use_extratrees=True, val_last=252, n_repeats=5, seed=42, w_corr=0.6, w_perm=0.4):\n",
    "    # 1) keep a small validation slice\n",
    "    if val_last is not None and len(X_va) > val_last:\n",
    "        Xv = X_va.iloc[-val_last:].astype(np.float32).copy()\n",
    "        yv = y_va.iloc[-val_last:].to_numpy()\n",
    "    else:\n",
    "        Xv = X_va.astype(np.float32).copy()\n",
    "        yv = y_va.to_numpy()\n",
    "\n",
    "    # 2) univariate Pearson on TRAIN; take top N\n",
    "    corr_abs = X_tr.apply(lambda c: np.corrcoef(c, y_tr)[0,1], axis=0).abs().fillna(0.0)\n",
    "    cand = corr_abs.sort_values(ascending=False).head(min(top_corr, X_tr.shape[1])).index.tolist()\n",
    "\n",
    "    # 3) small, fast tree on TRAIN\n",
    "    Tree = ExtraTreesRegressor if use_extratrees else RandomForestRegressor\n",
    "    tree = Tree(\n",
    "        n_estimators=100, max_depth=8, min_samples_leaf=0.01, max_features=0.7,\n",
    "        n_jobs=-1, random_state=seed\n",
    "    ).fit(X_tr[cand].astype(np.float32), y_tr.to_numpy())\n",
    "\n",
    "    # 4) permutation importance on VALID (few repeats, parallel)\n",
    "    pi = permutation_importance(tree, Xv[cand], yv, n_repeats=n_repeats,\n",
    "                                random_state=seed, scoring=\"neg_mean_squared_error\", n_jobs=-1)\n",
    "    perm = pd.Series(np.clip(pi.importances_mean, 0, None), index=cand)\n",
    "\n",
    "    # 5) combine by rank (robust to scaling)\n",
    "    r_corr = corr_abs.loc[cand].rank(ascending=False)\n",
    "    r_perm = perm.rank(ascending=False)\n",
    "    score = (w_corr * r_corr + w_perm * r_perm).sort_values(ascending=False)\n",
    "\n",
    "    selected = score.index[:min(k, len(score))].tolist()\n",
    "    summary = pd.DataFrame({\"corr_abs\": corr_abs.loc[cand], \"perm\": perm, \"score_rank\": score}).loc[score.index]\n",
    "    return selected, summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b2d253ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_train(X_train, y_train, features = None, C=1.0):\n",
    "    \"\"\"\n",
    "    Train a Logistic regression model and evaluate on validation set.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train : pd.DataFrame\n",
    "        Training features.\n",
    "    y_train : pd.Series\n",
    "        Training target.\n",
    "   \n",
    "    C : float, default 1.0\n",
    "        Inverse of regularization strength for Logistic regression.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model : LogisticRegression\n",
    "        Trained Logistic regression model.\n",
    "    \n",
    "    \"\"\"\n",
    "    model = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('logistic', LogisticRegression(C=C, max_iter=1000))\n",
    "    ])\n",
    "\n",
    "    if features:\n",
    "        model.fit(X_train[features], y_train)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c4d4ec43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trees_train(X_train, y_train, features = None, type='RandomForest'):\n",
    "    \"\"\"\n",
    "    Train a Tree Regressor and evaluate on validation set.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train : pd.DataFrame\n",
    "        Training features.\n",
    "    y_train : pd.Series\n",
    "        Training target.\n",
    "   \n",
    "    n_estimators : int, default 100\n",
    "        Number of trees in the forest.\n",
    "    \n",
    "    max_depth : int or None, default None\n",
    "        Maximum depth of the tree.\n",
    "\n",
    "    random_state : int, default 42\n",
    "        Random seed for reproducibility.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model : Regressor\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if type == 'RandomForest':\n",
    "        model = RandomForestRegressor(n_estimators=100,\n",
    "            max_depth=8,\n",
    "            min_samples_leaf=0.01,     # 1% of samples per leaf (robust)\n",
    "            min_samples_split=0.02,\n",
    "            max_features=0.7,\n",
    "            bootstrap=True,\n",
    "            n_jobs=-1, random_state=42)\n",
    "        \n",
    "    elif type == 'ExtraTrees':\n",
    "        model = ExtraTreesRegressor(\n",
    "            n_estimators=100,\n",
    "            max_depth=8,\n",
    "            min_samples_leaf=0.01,\n",
    "            min_samples_split=0.02,\n",
    "            max_features=0.7,\n",
    "            bootstrap=False,\n",
    "            n_jobs=-1, random_state=42\n",
    "        )\n",
    "\n",
    "    elif type == 'XGBoost':\n",
    "        model = XGBRegressor(\n",
    "            n_estimators=100,\n",
    "            learning_rate=0.10,\n",
    "            max_depth=4,\n",
    "            subsample=0.7,\n",
    "            colsample_bytree=0.7,\n",
    "            min_child_weight=10,       # combats noise\n",
    "            reg_lambda=2.0,\n",
    "            objective=\"reg:squarederror\",\n",
    "            n_jobs=-1, random_state=42\n",
    "        )\n",
    "    elif type == 'LightGBM':\n",
    "        model = LGBMRegressor(\n",
    "            verbosity = -1,\n",
    "            n_estimators=100,\n",
    "            learning_rate=0.10,\n",
    "            max_depth=6,\n",
    "            num_leaves=31,             # <= 2^max_depth for safety\n",
    "            min_data_in_leaf=100,      # robust on small-signal data\n",
    "            feature_fraction=0.7,\n",
    "            bagging_fraction=0.7,\n",
    "            bagging_freq=1,\n",
    "            lambda_l2=5.0,\n",
    "            extra_trees=True,          # adds randomness like ExtraTrees\n",
    "            n_jobs=-1, random_state=42\n",
    "        )\n",
    "    if features:\n",
    "        model.fit(X_train[features], y_train)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "bbe00578",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_calibrate(pred_train, y_train, *, dropna: bool = True, fit_intercept: bool = True):\n",
    "    \"\"\"\n",
    "    Fit a scikit-learn LinearRegression on TRAIN predictions:\n",
    "        y = alpha + beta * pred\n",
    "\n",
    "    Returns a Pipeline that reshapes 1D inputs and applies the fitted LinearRegression.\n",
    "    You can call .predict(...) on it with a 1D array/list/Series of predictions.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pred_train : array-like, shape (n_samples,)\n",
    "        Model predictions on the training window (e.g., your tree's outputs).\n",
    "    y_train : array-like, shape (n_samples,)\n",
    "        Realized targets on the training window (e.g., next-day returns).\n",
    "    dropna : bool, default True\n",
    "        Drop pairs with NaN/Inf before fitting. If False and NaNs exist, raises ValueError.\n",
    "    fit_intercept : bool, default True\n",
    "        Passed to LinearRegression.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model : sklearn Pipeline\n",
    "        Use model.predict(new_pred) to get calibrated predictions.\n",
    "        Access alpha/beta via:\n",
    "            alpha = model.named_steps['lr'].intercept_\n",
    "            beta  = model.named_steps['lr'].coef_[0]\n",
    "    \"\"\"\n",
    "    x = np.asarray(pred_train, dtype=float).flatten()\n",
    "    y = np.asarray(y_train, dtype=float).flatten()\n",
    "    if x.shape != y.shape:\n",
    "        raise ValueError(\"pred_train and y_train must have the same shape\")\n",
    "\n",
    "    mask = np.isfinite(x) & np.isfinite(y)\n",
    "    if not dropna and not mask.all():\n",
    "        raise ValueError(\"NaNs/Infs present; set dropna=True to filter them out.\")\n",
    "    x, y = x[mask], y[mask]\n",
    "    if x.size < 2:\n",
    "        raise ValueError(\"Not enough data to calibrate (need ≥2 finite pairs).\")\n",
    "\n",
    "    # Pipeline so you can pass 1D arrays to .predict() without manual reshape\n",
    "    model = Pipeline(steps=[\n",
    "        (\"reshape\", FunctionTransformer(lambda z: np.asarray(z, dtype=float).reshape(-1, 1), validate=False)),\n",
    "        (\"lr\", LinearRegression(fit_intercept=fit_intercept)),\n",
    "    ])\n",
    "    model.fit(x, y)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4df3bcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_predict(model, X, calibrate_model):\n",
    "    \"\"\"\n",
    "    Generate predictions using the trained model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : Trained model\n",
    "        The trained regression model.\n",
    "    X : pd.DataFrame\n",
    "        Features for prediction.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    y_pred : np.ndarray\n",
    "        Predicted values.\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X)\n",
    "\n",
    "    calibrated_pred = calibrate_model.predict(y_pred)\n",
    "    return calibrated_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0640572d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_lag_features(df, cols, lags=(1, 5, 20), *, keep_original=True, dtype=\"float32\"):\n",
    "    \"\"\"\n",
    "    Returns a new DataFrame with optional originals + lagged copies.\n",
    "    Uses shift(L), so expect NaNs at the head.\n",
    "    \"\"\"\n",
    "    out = pd.DataFrame(index=df.index)\n",
    "    if keep_original:\n",
    "        out[cols] = df[cols]\n",
    "    for L in lags:\n",
    "        out[[f\"{c}_lag{L}\" for c in cols]] = df[cols].shift(L)\n",
    "    if dtype is not None:\n",
    "        for c in out.columns:\n",
    "            if pd.api.types.is_float_dtype(out[c]):\n",
    "                out[c] = out[c].astype(dtype)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2230d814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Rolling stats (+ optional z-scores), time-safe via past_only=True\n",
    "def make_rolling_features(\n",
    "    df, cols,\n",
    "    windows=(5, 20),\n",
    "    *,\n",
    "    stats=(\"mean\", \"std\"),     # any of: \"mean\",\"std\",\"min\",\"max\",\"sum\"\n",
    "    zscore: bool = False,       # z_t = (x_t - mean_{past}) / (std_{past}+eps)\n",
    "    past_only: bool = True,    # shift(1) inside rolling to avoid leakage\n",
    "    min_periods: int = None,  # default = window size\n",
    "    eps: float = 1e-9,\n",
    "    dtype: str = \"float32\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Builds rolling features for each col over each window.\n",
    "    If past_only=True, the rolling window excludes the current row (safe for t+1 targets).\n",
    "    \"\"\"\n",
    "    out = pd.DataFrame(index=df.index)\n",
    "    for w in windows:\n",
    "        mp = w if min_periods is None else min_periods\n",
    "        base = df[cols].shift(1) if past_only else df[cols]\n",
    "        roll = base.rolling(window=w, min_periods=mp)\n",
    "\n",
    "        if \"mean\" in stats:\n",
    "            m = roll.mean()\n",
    "            out[[f\"{c}_rollmean{w}\" for c in cols]] = m\n",
    "        if \"std\" in stats:\n",
    "            s = roll.std(ddof=0)\n",
    "            out[[f\"{c}_rollstd{w}\" for c in cols]] = s\n",
    "        if \"min\" in stats:\n",
    "            out[[f\"{c}_rollmin{w}\" for c in cols]] = roll.min()\n",
    "        if \"max\" in stats:\n",
    "            out[[f\"{c}_rollmax{w}\" for c in cols]] = roll.max()\n",
    "        if \"sum\" in stats:\n",
    "            out[[f\"{c}_rollsum{w}\" for c in cols]] = roll.sum()\n",
    "\n",
    "        if zscore:\n",
    "            # need mean & std; compute if not already available\n",
    "            if \"mean\" in stats:\n",
    "                m = out[[f\"{c}_rollmean{w}\" for c in cols]].copy()\n",
    "                m.columns = cols\n",
    "            else:\n",
    "                m = roll.mean()\n",
    "            if \"std\" in stats:\n",
    "                s = out[[f\"{c}_rollstd{w}\" for c in cols]].copy()\n",
    "                s.columns = cols\n",
    "            else:\n",
    "                s = roll.std(ddof=0)\n",
    "            for c in cols:\n",
    "                out[f\"{c}_z{w}\"] = (df[c] - m[c]) / (s[c] + eps)\n",
    "\n",
    "    if dtype is not None:\n",
    "        for c in out.columns:\n",
    "            if pd.api.types.is_float_dtype(out[c]):\n",
    "                out[c] = out[c].astype(dtype)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "43811eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_features, regression_feature_summary = feature_selection(X_train_cleaned, y_train, X_features_train_cleaned, y_features_train, w_corr=0.9, w_perm=0.1, k = 30, top_corr=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "6fbb4f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_y = [1 if x > 0 else 0 for x in list(np.asarray(y_train).flatten())]\n",
    "logistic = logistic_train(X_train_cleaned, pd.Series(logistic_y), features = regression_features, C=1.0)\n",
    "logistic_predict_train = logistic.predict_proba(X_train_cleaned[regression_features])\n",
    "logistic_calibrate_model = linear_calibrate(logistic_predict_train[:,1], y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a0c03e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "btree_features, btree_feature_summary = feature_selection(X_train_cleaned, y_train, X_features_train_cleaned, y_features_train, w_corr=0.7, w_perm=0.3, k = 200, top_corr=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "493dcd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lightgbm = trees_train(X_train_cleaned, y_train, features=btree_features, type='LightGBM')\n",
    "lightgbm_predict_train = lightgbm.predict(X_train_cleaned[btree_features])\n",
    "lightgbm_calibrate_model = linear_calibrate(lightgbm_predict_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "d9c2ef8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_features, tree_feature_summary = feature_selection(X_train_cleaned, y_train, X_features_train_cleaned, y_features_train, w_corr=0.7, w_perm=0.3, k = 30, top_corr=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ed312b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = trees_train(X_train_cleaned, y_train, features=tree_features, type='RandomForest')\n",
    "rf_predict_train = rf.predict(X_train_cleaned[tree_features])\n",
    "rf_calibrate_model = linear_calibrate(rf_predict_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "6ee8b067",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ewma_step(prev_var: float, prev_ret: float, lam: float = 0.94) -> float:\n",
    "    \"\"\"Given yesterday's variance v_t and return r_t (same units you trained on),\n",
    "    return v_{t+1} = λ v_t + (1-λ) r_t^2.\"\"\"\n",
    "    #print(lam, prev_var, prev_ret)\n",
    "    return lam * float(prev_var) + (1.0 - lam) * (float(prev_ret) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721cf982",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test: pd.DataFrame) -> float:\n",
    "    X_test = test.drop(columns = ['forward_returns', 'market_forward_excess_returns', 'risk_free_rate', 'date_id'])\n",
    "    global X_hist\n",
    "    global rf\n",
    "    global rf_calibrate_model\n",
    "    global logistic\n",
    "    global logistic_calibrate_model\n",
    "    global lightgbm\n",
    "    global lightgbm_calibrate_model\n",
    "    global regression_features\n",
    "    global tree_features\n",
    "    global btree_features\n",
    "    global tree_var_features\n",
    "    global tree_model\n",
    "    global good_features\n",
    "    global prev_var\n",
    "    global prev_ret\n",
    "    global alpha\n",
    "    global beta\n",
    "    global omega\n",
    "    print(X_test)\n",
    "    print(X_hist)\n",
    "  \n",
    "    X_hist = pd.concat([X_hist,X_test], ignore_index = True)\n",
    "    #print(prev_var, prev_ret)\n",
    "\n",
    "    X_enriched_hist = make_rolling_features(make_lag_features(X_hist, good_features, lags = (1, 2, 5, 20)), good_features)\n",
    "    X_enriched_hist_cleaned = X_enriched_hist.ffill().fillna(0)\n",
    "    X_enriched_test = X_enriched_hist_cleaned.iloc[-1:]\n",
    "    logistic_mean = mean_predict(logistic, X_enriched_test[regression_features], logistic_calibrate_model)\n",
    "    lightgbm_mean = mean_predict(lightgbm, X_enriched_test[btree_features], lightgbm_calibrate_model)\n",
    "    rf_mean = mean_predict(rf, X_enriched_test[tree_features], rf_calibrate_model)\n",
    "    ensemble_mean = (0.3*logistic_mean + 0.4*lightgbm_mean + 0.3*rf_mean)[0]\n",
    "    ewma_var = ewma_step(prev_var, prev_ret)\n",
    "    # garch_var = garch_step(prev_var, prev_ret, alpha, beta, omega)\n",
    "    # tree_var = tree_step(tree_model, X_enriched_test[tree_var_features])\n",
    "    #print(ewma_var, garch_var, tree_var)\n",
    "    ensemble_var = (1*ewma_var)\n",
    "    prev_ret = ensemble_mean\n",
    "    prev_var = ensemble_var\n",
    "\n",
    "    #print(ensemble_mean, ensemble_var)\n",
    "    w = min(max(0, min(ensemble_mean/(8*ensemble_var), ensemble_mean*200)), 2)\n",
    "    print(ensemble_mean, ensemble_var, ensemble_mean/(10*ensemble_var),w)\n",
    "    return float(w), ensemble_mean, logistic_mean, lightgbm_mean, rf_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "a752562c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loc = 7192\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "0b798861",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train = pd.read_csv('X_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "44ddb284",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tests = pd.read_csv('train.csv').iloc[test_loc:]\n",
    "y_tests = X_tests[['forward_returns', 'market_forward_excess_returns', 'risk_free_rate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "b77b3f0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D1_rollmean5</th>\n",
       "      <th>D2_rollmean5</th>\n",
       "      <th>D3_rollmean5</th>\n",
       "      <th>D4_rollmean5</th>\n",
       "      <th>D5_rollmean5</th>\n",
       "      <th>D6_rollmean5</th>\n",
       "      <th>D7_rollmean5</th>\n",
       "      <th>D8_rollmean5</th>\n",
       "      <th>D9_rollmean5</th>\n",
       "      <th>E1_rollmean5</th>\n",
       "      <th>...</th>\n",
       "      <th>V11_rollstd20</th>\n",
       "      <th>V12_rollstd20</th>\n",
       "      <th>V13_rollstd20</th>\n",
       "      <th>V2_rollstd20</th>\n",
       "      <th>V3_rollstd20</th>\n",
       "      <th>V4_rollstd20</th>\n",
       "      <th>V5_rollstd20</th>\n",
       "      <th>V6_rollstd20</th>\n",
       "      <th>V7_rollstd20</th>\n",
       "      <th>V8_rollstd20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6940</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.715571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112619</td>\n",
       "      <td>0.203303</td>\n",
       "      <td>0.075878</td>\n",
       "      <td>0.058565</td>\n",
       "      <td>0.137396</td>\n",
       "      <td>0.025455</td>\n",
       "      <td>0.539845</td>\n",
       "      <td>0.155436</td>\n",
       "      <td>0.121786</td>\n",
       "      <td>0.047750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6941</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.714518</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108789</td>\n",
       "      <td>0.191063</td>\n",
       "      <td>0.076502</td>\n",
       "      <td>0.055130</td>\n",
       "      <td>0.140583</td>\n",
       "      <td>0.031152</td>\n",
       "      <td>0.586112</td>\n",
       "      <td>0.154636</td>\n",
       "      <td>0.124032</td>\n",
       "      <td>0.046827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6942</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.713465</td>\n",
       "      <td>...</td>\n",
       "      <td>0.107945</td>\n",
       "      <td>0.194004</td>\n",
       "      <td>0.077238</td>\n",
       "      <td>0.052311</td>\n",
       "      <td>0.137758</td>\n",
       "      <td>0.031804</td>\n",
       "      <td>0.571162</td>\n",
       "      <td>0.157478</td>\n",
       "      <td>0.127434</td>\n",
       "      <td>0.047042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6943</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.712414</td>\n",
       "      <td>...</td>\n",
       "      <td>0.107272</td>\n",
       "      <td>0.194644</td>\n",
       "      <td>0.078845</td>\n",
       "      <td>0.050736</td>\n",
       "      <td>0.134478</td>\n",
       "      <td>0.031201</td>\n",
       "      <td>0.589364</td>\n",
       "      <td>0.153907</td>\n",
       "      <td>0.132294</td>\n",
       "      <td>0.046997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6944</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.711362</td>\n",
       "      <td>...</td>\n",
       "      <td>0.107225</td>\n",
       "      <td>0.194362</td>\n",
       "      <td>0.081285</td>\n",
       "      <td>0.049739</td>\n",
       "      <td>0.142204</td>\n",
       "      <td>0.031065</td>\n",
       "      <td>0.587173</td>\n",
       "      <td>0.159326</td>\n",
       "      <td>0.138731</td>\n",
       "      <td>0.047024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7187</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.068772</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105407</td>\n",
       "      <td>0.169268</td>\n",
       "      <td>0.561259</td>\n",
       "      <td>0.034088</td>\n",
       "      <td>0.177390</td>\n",
       "      <td>0.020063</td>\n",
       "      <td>0.403754</td>\n",
       "      <td>0.191928</td>\n",
       "      <td>0.508592</td>\n",
       "      <td>0.006913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7188</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.067526</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105115</td>\n",
       "      <td>0.170534</td>\n",
       "      <td>0.547991</td>\n",
       "      <td>0.034827</td>\n",
       "      <td>0.185225</td>\n",
       "      <td>0.019414</td>\n",
       "      <td>0.403754</td>\n",
       "      <td>0.192869</td>\n",
       "      <td>0.495477</td>\n",
       "      <td>0.007027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7189</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.066283</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100689</td>\n",
       "      <td>0.167621</td>\n",
       "      <td>0.554014</td>\n",
       "      <td>0.034569</td>\n",
       "      <td>0.184154</td>\n",
       "      <td>0.019306</td>\n",
       "      <td>0.392002</td>\n",
       "      <td>0.193821</td>\n",
       "      <td>0.499186</td>\n",
       "      <td>0.006981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7190</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.065042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096758</td>\n",
       "      <td>0.165098</td>\n",
       "      <td>0.554706</td>\n",
       "      <td>0.035329</td>\n",
       "      <td>0.182496</td>\n",
       "      <td>0.020616</td>\n",
       "      <td>0.381425</td>\n",
       "      <td>0.197756</td>\n",
       "      <td>0.497592</td>\n",
       "      <td>0.007026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7191</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.063803</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091092</td>\n",
       "      <td>0.159169</td>\n",
       "      <td>0.543343</td>\n",
       "      <td>0.036759</td>\n",
       "      <td>0.183773</td>\n",
       "      <td>0.022556</td>\n",
       "      <td>0.379455</td>\n",
       "      <td>0.197355</td>\n",
       "      <td>0.484544</td>\n",
       "      <td>0.006877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252 rows × 344 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      D1_rollmean5  D2_rollmean5  D3_rollmean5  D4_rollmean5  D5_rollmean5  \\\n",
       "6940           0.0           0.0           0.2           0.0           0.0   \n",
       "6941           0.0           0.0           0.2           0.0           0.0   \n",
       "6942           0.0           0.0           0.0           0.0           0.0   \n",
       "6943           0.0           0.0           0.0           0.0           0.0   \n",
       "6944           0.0           0.0           0.0           0.0           0.0   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "7187           0.0           0.0           0.2           0.0           0.2   \n",
       "7188           0.0           0.0           0.2           0.0           0.0   \n",
       "7189           0.0           0.0           0.2           0.0           0.0   \n",
       "7190           0.0           0.0           0.2           0.0           0.0   \n",
       "7191           0.0           0.0           0.2           0.0           0.0   \n",
       "\n",
       "      D6_rollmean5  D7_rollmean5  D8_rollmean5  D9_rollmean5  E1_rollmean5  \\\n",
       "6940           0.0           0.0           0.0           0.0      0.715571   \n",
       "6941           0.0           0.0           0.0           0.0      0.714518   \n",
       "6942           0.0           0.0           0.0           0.0      0.713465   \n",
       "6943          -0.2           0.0           0.0           0.0      0.712414   \n",
       "6944          -0.4           0.0           0.0           0.0      0.711362   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "7187           0.0           0.2           0.0           0.4      1.068772   \n",
       "7188           0.0           0.2           0.0           0.2      1.067526   \n",
       "7189           0.0           0.0           0.0           0.0      1.066283   \n",
       "7190           0.0           0.0           0.0           0.0      1.065042   \n",
       "7191           0.0           0.0           0.0           0.0      1.063803   \n",
       "\n",
       "      ...  V11_rollstd20  V12_rollstd20  V13_rollstd20  V2_rollstd20  \\\n",
       "6940  ...       0.112619       0.203303       0.075878      0.058565   \n",
       "6941  ...       0.108789       0.191063       0.076502      0.055130   \n",
       "6942  ...       0.107945       0.194004       0.077238      0.052311   \n",
       "6943  ...       0.107272       0.194644       0.078845      0.050736   \n",
       "6944  ...       0.107225       0.194362       0.081285      0.049739   \n",
       "...   ...            ...            ...            ...           ...   \n",
       "7187  ...       0.105407       0.169268       0.561259      0.034088   \n",
       "7188  ...       0.105115       0.170534       0.547991      0.034827   \n",
       "7189  ...       0.100689       0.167621       0.554014      0.034569   \n",
       "7190  ...       0.096758       0.165098       0.554706      0.035329   \n",
       "7191  ...       0.091092       0.159169       0.543343      0.036759   \n",
       "\n",
       "      V3_rollstd20  V4_rollstd20  V5_rollstd20  V6_rollstd20  V7_rollstd20  \\\n",
       "6940      0.137396      0.025455      0.539845      0.155436      0.121786   \n",
       "6941      0.140583      0.031152      0.586112      0.154636      0.124032   \n",
       "6942      0.137758      0.031804      0.571162      0.157478      0.127434   \n",
       "6943      0.134478      0.031201      0.589364      0.153907      0.132294   \n",
       "6944      0.142204      0.031065      0.587173      0.159326      0.138731   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "7187      0.177390      0.020063      0.403754      0.191928      0.508592   \n",
       "7188      0.185225      0.019414      0.403754      0.192869      0.495477   \n",
       "7189      0.184154      0.019306      0.392002      0.193821      0.499186   \n",
       "7190      0.182496      0.020616      0.381425      0.197756      0.497592   \n",
       "7191      0.183773      0.022556      0.379455      0.197355      0.484544   \n",
       "\n",
       "      V8_rollstd20  \n",
       "6940      0.047750  \n",
       "6941      0.046827  \n",
       "6942      0.047042  \n",
       "6943      0.046997  \n",
       "6944      0.047024  \n",
       "...            ...  \n",
       "7187      0.006913  \n",
       "7188      0.007027  \n",
       "7189      0.006981  \n",
       "7190      0.007026  \n",
       "7191      0.006877  \n",
       "\n",
       "[252 rows x 344 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_features_train_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "66224e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_id</th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>D3</th>\n",
       "      <th>D4</th>\n",
       "      <th>D5</th>\n",
       "      <th>D6</th>\n",
       "      <th>D7</th>\n",
       "      <th>D8</th>\n",
       "      <th>D9</th>\n",
       "      <th>...</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>forward_returns</th>\n",
       "      <th>risk_free_rate</th>\n",
       "      <th>market_forward_excess_returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7192</th>\n",
       "      <td>7192</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.550265</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>2.808941</td>\n",
       "      <td>0.128307</td>\n",
       "      <td>-0.710536</td>\n",
       "      <td>0.973545</td>\n",
       "      <td>-0.728618</td>\n",
       "      <td>-0.003771</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>-0.004158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7193</th>\n",
       "      <td>7193</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.886243</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>3.405066</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>-0.499816</td>\n",
       "      <td>0.955357</td>\n",
       "      <td>-0.531049</td>\n",
       "      <td>-0.001143</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>-0.001529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7194</th>\n",
       "      <td>7194</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.599206</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>2.969902</td>\n",
       "      <td>0.102513</td>\n",
       "      <td>-0.501887</td>\n",
       "      <td>0.957011</td>\n",
       "      <td>-0.492945</td>\n",
       "      <td>0.001859</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.001474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7195</th>\n",
       "      <td>7195</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.667328</td>\n",
       "      <td>0.867063</td>\n",
       "      <td>3.184580</td>\n",
       "      <td>0.138228</td>\n",
       "      <td>-0.566672</td>\n",
       "      <td>0.948082</td>\n",
       "      <td>-0.566723</td>\n",
       "      <td>0.005032</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.004647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7196</th>\n",
       "      <td>7196</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.697090</td>\n",
       "      <td>0.876323</td>\n",
       "      <td>3.309322</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>-0.623320</td>\n",
       "      <td>0.970899</td>\n",
       "      <td>-0.620151</td>\n",
       "      <td>0.008522</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.008136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8985</th>\n",
       "      <td>8985</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.469577</td>\n",
       "      <td>0.837963</td>\n",
       "      <td>1.226772</td>\n",
       "      <td>0.822751</td>\n",
       "      <td>-0.707361</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>-0.649616</td>\n",
       "      <td>0.002457</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.001990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8986</th>\n",
       "      <td>8986</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.671958</td>\n",
       "      <td>0.837963</td>\n",
       "      <td>0.785877</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>-0.715692</td>\n",
       "      <td>0.196098</td>\n",
       "      <td>-0.668289</td>\n",
       "      <td>0.002312</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.001845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8987</th>\n",
       "      <td>8987</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.787698</td>\n",
       "      <td>0.834898</td>\n",
       "      <td>0.823413</td>\n",
       "      <td>-0.723949</td>\n",
       "      <td>0.133929</td>\n",
       "      <td>-0.670946</td>\n",
       "      <td>0.002891</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.002424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8988</th>\n",
       "      <td>8988</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.655423</td>\n",
       "      <td>0.783730</td>\n",
       "      <td>0.994026</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>-0.684937</td>\n",
       "      <td>0.101852</td>\n",
       "      <td>-0.646265</td>\n",
       "      <td>0.008310</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.007843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8989</th>\n",
       "      <td>8989</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066799</td>\n",
       "      <td>0.783730</td>\n",
       "      <td>1.068037</td>\n",
       "      <td>0.879630</td>\n",
       "      <td>-0.764806</td>\n",
       "      <td>0.079034</td>\n",
       "      <td>-0.705662</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>-0.000368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1798 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      date_id  D1  D2  D3  D4  D5  D6  D7  D8  D9  ...        V3        V4  \\\n",
       "7192     7192   0   0   0   0   0   0   0   0   0  ...  0.550265  0.875000   \n",
       "7193     7193   0   0   0   0   0   0   0   0   0  ...  0.886243  0.870370   \n",
       "7194     7194   0   0   0   0   0  -1   0   0   0  ...  0.599206  0.875000   \n",
       "7195     7195   0   0   0   0   0  -1   0   0   0  ...  0.667328  0.867063   \n",
       "7196     7196   0   0   0   0   0  -1   0   0   0  ...  0.697090  0.876323   \n",
       "...       ...  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...       ...       ...   \n",
       "8985     8985   0   0   0   0   0   0   0   0   0  ...  0.469577  0.837963   \n",
       "8986     8986   0   0   0   0   0   0   0   0   0  ...  0.671958  0.837963   \n",
       "8987     8987   0   0   1   0   0   0   0   0   0  ...  0.481481  0.787698   \n",
       "8988     8988   0   0   0   0   0   0   0   0   0  ...  0.655423  0.783730   \n",
       "8989     8989   0   0   0   0   0   0   0   0   0  ...  0.066799  0.783730   \n",
       "\n",
       "            V5        V6        V7        V8        V9  forward_returns  \\\n",
       "7192  2.808941  0.128307 -0.710536  0.973545 -0.728618        -0.003771   \n",
       "7193  3.405066  0.074074 -0.499816  0.955357 -0.531049        -0.001143   \n",
       "7194  2.969902  0.102513 -0.501887  0.957011 -0.492945         0.001859   \n",
       "7195  3.184580  0.138228 -0.566672  0.948082 -0.566723         0.005032   \n",
       "7196  3.309322  0.138889 -0.623320  0.970899 -0.620151         0.008522   \n",
       "...        ...       ...       ...       ...       ...              ...   \n",
       "8985  1.226772  0.822751 -0.707361  0.142857 -0.649616         0.002457   \n",
       "8986  0.785877  0.805556 -0.715692  0.196098 -0.668289         0.002312   \n",
       "8987  0.834898  0.823413 -0.723949  0.133929 -0.670946         0.002891   \n",
       "8988  0.994026  0.851852 -0.684937  0.101852 -0.646265         0.008310   \n",
       "8989  1.068037  0.879630 -0.764806  0.079034 -0.705662         0.000099   \n",
       "\n",
       "      risk_free_rate  market_forward_excess_returns  \n",
       "7192        0.000078                      -0.004158  \n",
       "7193        0.000077                      -0.001529  \n",
       "7194        0.000077                       0.001474  \n",
       "7195        0.000076                       0.004647  \n",
       "7196        0.000078                       0.008136  \n",
       "...              ...                            ...  \n",
       "8985        0.000155                       0.001990  \n",
       "8986        0.000156                       0.001845  \n",
       "8987        0.000156                       0.002424  \n",
       "8988        0.000156                       0.007843  \n",
       "8989        0.000156                      -0.000368  \n",
       "\n",
       "[1798 rows x 98 columns]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "9b29dfa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      D1  D2  D3  D4  D5  D6  D7  D8  D9        E1  ...       V12       V13  \\\n",
      "7167   1   1   1   0   0   0   0   0   0  1.090323  ...  0.763228 -0.622539   \n",
      "7168   0   0   0   0   0   0   0   0   0  1.089036  ...  0.890873 -0.423329   \n",
      "7169   0   0   0   0   0   0   0   0   0  1.087750  ...  0.872354 -0.621087   \n",
      "7170   0   0   0   0   0   0   0   0   0  1.086468  ...  0.930556 -0.656546   \n",
      "7171   0   0   0   0   0   0   0   0   0  1.085188  ...  0.909392 -0.545416   \n",
      "7172   0   0   0   0   0   0   0   0   0  1.083910  ...  0.911376 -0.247013   \n",
      "7173   0   0   0   0   0  -1   0   0   0  1.082635  ...  0.824735 -0.380386   \n",
      "7174   0   0   0   0   0  -1   0   0   0  1.081362  ...  0.798942  0.170880   \n",
      "7175   0   0   0   0   0  -1   0   0   0  1.080092  ...  0.761243 -0.087064   \n",
      "7176   0   0   0   0   0  -1   0   0   0  1.078824  ...  0.891534  1.038756   \n",
      "7177   0   0   0   0   0  -1   0   0   0  1.077559  ...  0.881944  0.497164   \n",
      "7178   0   0   0   0   0   0   0   1   0  1.076296  ...  0.883598  1.157713   \n",
      "7179   0   0   0   0   1   0   0   1   0  1.075035  ...  0.845238  0.656033   \n",
      "7180   0   0   0   0   1   0   0   1   0  1.073777  ...  0.796958  0.395813   \n",
      "7181   0   0   0   0   1   0   0   0   1  1.072522  ...  0.774140  0.194802   \n",
      "7182   0   0   0   0   1   0   0   0   1  1.071269  ...  0.545635  0.435199   \n",
      "7183   0   0   0   0   0   0   1   0   1  1.070018  ...  0.406085  0.029496   \n",
      "7184   0   0   0   0   0   0   0   0   0  1.068770  ...  0.375000 -0.458264   \n",
      "7185   0   0   0   0   0   0   0   0   0  1.067524  ...  0.536376 -0.606802   \n",
      "7186   0   0   1   0   0   0   0   0   0  1.066280  ...  0.566138 -0.581493   \n",
      "7187   0   0   0   0   0   0   0   0   0  1.065040  ...  0.662698 -0.276683   \n",
      "7188   0   0   0   0   0   0   0   0   0  1.063801  ...  0.730159 -0.563242   \n",
      "7189   0   0   0   0   0   0   0   0   0  1.062565  ...  0.753968 -0.633782   \n",
      "7190   0   0   0   0   0   0   0   0   0  1.061331  ...  0.737103 -0.416334   \n",
      "7191   0   0   0   0   0   0   0   0   0  1.060100  ...  0.599206 -0.610762   \n",
      "\n",
      "            V2        V3        V4        V5        V6        V7        V8  \\\n",
      "7167  0.886243  0.758598  0.873016  1.476511  0.344577 -0.660567  0.998677   \n",
      "7168  0.906746  0.871032  0.885582  1.986607  0.340608 -0.497931  0.999339   \n",
      "7169  0.893519  0.878307  0.899471  1.840599  0.312831 -0.718175  0.999339   \n",
      "7170  0.888228  0.830026  0.894180  1.922751  0.476852 -0.755010  1.000000   \n",
      "7171  0.873677  0.939815  0.900132  1.726025  0.444444 -0.665010  1.000000   \n",
      "7172  0.858466  0.565476  0.908069  1.723087  0.562169 -0.382199  1.000000   \n",
      "7173  0.833995  0.836640  0.886243  1.514650  0.755291 -0.533058  1.000000   \n",
      "7174  0.816138  0.766534  0.884259  1.705218  0.536376 -0.030221  0.998677   \n",
      "7175  0.800265  0.867063  0.860450  1.586959  0.533069 -0.265709  0.994709   \n",
      "7176  0.919974  0.797619  0.910714  1.662980  0.388889  0.701224  1.000000   \n",
      "7177  0.910053  0.739418  0.912698  0.889750  0.261243  0.319207  0.997354   \n",
      "7178  0.928571  0.958333  0.928571  0.922666  0.066799  0.860139  1.000000   \n",
      "7179  0.921296  0.784392  0.929233  0.446276  0.040344  0.573046  0.998677   \n",
      "7180  0.912698  0.699735  0.927249  1.107283  0.025132  0.367198  0.998677   \n",
      "7181  0.903439  0.939153  0.915344  1.812062  0.100529  0.234667  0.998677   \n",
      "7182  0.904762  0.979497  0.943122  1.700570  0.082011  0.382555  0.984788   \n",
      "7183  0.891534  0.789021  0.900132  0.868735  0.212302  0.064198  0.982143   \n",
      "7184  0.875661  0.167328  0.900132  1.561990  0.312169 -0.371156  0.977513   \n",
      "7185  0.861111  0.610450  0.904101  1.711695  0.305556 -0.555725  0.986772   \n",
      "7186  0.873016  0.909392  0.882275  1.439031  0.287037 -0.568519  0.987765   \n",
      "7187  0.849868  0.539683  0.883598  1.476379  0.226852 -0.298147  0.988095   \n",
      "7188  0.861111  0.815476  0.888228  1.158328  0.219577 -0.583421  0.991071   \n",
      "7189  0.841270  0.771164  0.869709  1.336420  0.126984 -0.691435  0.987434   \n",
      "7190  0.827381  0.882275  0.859127  1.892457  0.109788 -0.513384  0.992063   \n",
      "7191  0.824074  0.707011  0.881614  2.630874  0.091931 -0.722328  0.972222   \n",
      "\n",
      "            V9  \n",
      "7167 -0.676849  \n",
      "7168 -0.567139  \n",
      "7169 -0.738323  \n",
      "7170 -0.731105  \n",
      "7171 -0.710977  \n",
      "7172 -0.480336  \n",
      "7173 -0.606226  \n",
      "7174 -0.244090  \n",
      "7175 -0.366860  \n",
      "7176  0.310752  \n",
      "7177  0.094416  \n",
      "7178  0.491765  \n",
      "7179  0.315379  \n",
      "7180  0.188927  \n",
      "7181  0.126268  \n",
      "7182  0.262629  \n",
      "7183 -0.013519  \n",
      "7184 -0.289847  \n",
      "7185 -0.572951  \n",
      "7186 -0.626064  \n",
      "7187 -0.398543  \n",
      "7188 -0.607360  \n",
      "7189 -0.680801  \n",
      "7190 -0.574819  \n",
      "7191 -0.726252  \n",
      "\n",
      "[25 rows x 94 columns]\n",
      "      D1  D2  D3  D4  D5  D6  D7  D8  D9        E1  ...       V12       V13  \\\n",
      "7192   0   0   0   0   0   0   0   0   0  1.058871  ...  0.706019 -0.563259   \n",
      "\n",
      "           V2        V3     V4        V5        V6        V7        V8  \\\n",
      "7192  0.80754  0.550265  0.875  2.808941  0.128307 -0.710536  0.973545   \n",
      "\n",
      "            V9  \n",
      "7192 -0.728618  \n",
      "\n",
      "[1 rows x 94 columns]\n",
      "    D1_rollmean5  D2_rollmean5  D3_rollmean5  D4_rollmean5  D5_rollmean5  \\\n",
      "25           0.0           0.0           0.0           0.0           0.0   \n",
      "\n",
      "    D6_rollmean5  D7_rollmean5  D8_rollmean5  D9_rollmean5  E1_rollmean5  ...  \\\n",
      "25           0.0           0.0           0.0           0.0      1.062567  ...   \n",
      "\n",
      "    V11_rollstd20  V12_rollstd20  V13_rollstd20  V2_rollstd20  V3_rollstd20  \\\n",
      "25       0.091456       0.155976       0.546733      0.038285      0.179848   \n",
      "\n",
      "    V4_rollstd20  V5_rollstd20  V6_rollstd20  V7_rollstd20  V8_rollstd20  \n",
      "25      0.022895      0.459652      0.197608      0.488047      0.008069  \n",
      "\n",
      "[1 rows x 344 columns]\n",
      "-0.0040773722238540595 9.41767874291628e-05 -4.329487483230353 0\n"
     ]
    }
   ],
   "source": [
    "prev_var = 1e-4\n",
    "X_hist = raw_train[-25:]\n",
    "alpha = 0.10080081885102102\n",
    "beta = 0.880106446271156\n",
    "omega = 0.007218758128689602\n",
    "prev_ret = y_features_train.iloc[-1]\n",
    "positions = []\n",
    "predicted_returns = []\n",
    "logistic_mean_list = []\n",
    "lightgbm_mean_list = []\n",
    "rf_mean_list = []\n",
    "for i in range (1):\n",
    "\n",
    "    w, pred_return, logistic_mean, lightgbm_mean, rf_mean = predict(X_tests.iloc[i:i+1])\n",
    "    positions.append(w)\n",
    "    predicted_returns.append(pred_return)\n",
    "    logistic_mean_list.append(logistic_mean)\n",
    "    lightgbm_mean_list.append(lightgbm_mean)\n",
    "    rf_mean_list.append(rf_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ebd3fcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(solution: pd.DataFrame, submission) -> float:\n",
    "    \"\"\"\n",
    "    Calculates a custom evaluation metric (volatility-adjusted Sharpe ratio).\n",
    "\n",
    "    This metric penalizes strategies that take on significantly more volatility\n",
    "    than the underlying market.\n",
    "\n",
    "    Returns:\n",
    "        float: The calculated adjusted Sharpe ratio.\n",
    "    \"\"\"\n",
    "\n",
    "  \n",
    "    solution = solution.copy()\n",
    "    solution.loc[:, 'position'] = submission\n",
    "\n",
    "    solution['strategy_returns'] = solution['risk_free_rate'] * (1 - solution['position']) + solution['position'] * solution['forward_returns']\n",
    "\n",
    "    # Calculate strategy's Sharpe ratio\n",
    "    strategy_excess_returns = solution['strategy_returns'] - solution['risk_free_rate']\n",
    "    strategy_excess_cumulative = (1 + strategy_excess_returns).prod()\n",
    "    strategy_mean_excess_return = (strategy_excess_cumulative) ** (1 / len(solution)) - 1\n",
    "    strategy_std = solution['strategy_returns'].std()\n",
    "    trading_days_per_yr = 252\n",
    "    sharpe = strategy_mean_excess_return / strategy_std * np.sqrt(trading_days_per_yr)\n",
    "    strategy_volatility = float(strategy_std * np.sqrt(trading_days_per_yr) * 100)\n",
    "\n",
    "    # Calculate market return and volatility\n",
    "    market_excess_returns = solution['forward_returns'] - solution['risk_free_rate']\n",
    "    market_excess_cumulative = (1 + market_excess_returns).prod()\n",
    "    market_mean_excess_return = (market_excess_cumulative) ** (1 / len(solution)) - 1\n",
    "    market_std = solution['forward_returns'].std()\n",
    "\n",
    "\n",
    "    market_volatility = float(market_std * np.sqrt(trading_days_per_yr) * 100)\n",
    "\n",
    "\n",
    "    # Calculate the volatility penalty\n",
    "    excess_vol = max(0, strategy_volatility / market_volatility - 1.2) if market_volatility > 0 else 0\n",
    "    vol_penalty = 1 + excess_vol\n",
    "\n",
    "    # Calculate the return penalty\n",
    "    return_gap = max(\n",
    "        0,\n",
    "        (market_mean_excess_return - strategy_mean_excess_return) * 100 * trading_days_per_yr,\n",
    "    )\n",
    "    return_penalty = 1 + (return_gap**2) / 100\n",
    "\n",
    "    # Adjust the Sharpe ratio by the volatility and return penalty\n",
    "    adjusted_sharpe = sharpe / (vol_penalty * return_penalty)\n",
    "    return min(float(adjusted_sharpe), 1_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "7f9120f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6420136080214519"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(y_tests, [1.0]*len(y_tests))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "3602ad2b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (1) does not match length of index (1798)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[165], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_tests\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpositions\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[163], line 14\u001b[0m, in \u001b[0;36mscore\u001b[0;34m(solution, submission)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mCalculates a custom evaluation metric (volatility-adjusted Sharpe ratio).\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m    float: The calculated adjusted Sharpe ratio.\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     13\u001b[0m solution \u001b[38;5;241m=\u001b[39m solution\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m---> 14\u001b[0m \u001b[43msolution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mposition\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m submission\n\u001b[1;32m     16\u001b[0m solution[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrategy_returns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m solution[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrisk_free_rate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m solution[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mposition\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m+\u001b[39m solution[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mposition\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m solution[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforward_returns\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Calculate strategy's Sharpe ratio\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Python-WorkSpace/kaggle/kaggle_hull_tactic_2025/.venv/lib/python3.9/site-packages/pandas/core/indexing.py:912\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[1;32m    911\u001b[0m iloc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc\n\u001b[0;32m--> 912\u001b[0m \u001b[43miloc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Python-WorkSpace/kaggle/kaggle_hull_tactic_2025/.venv/lib/python3.9/site-packages/pandas/core/indexing.py:1858\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[38;5;66;03m# add a new item with the dtype setup\u001b[39;00m\n\u001b[1;32m   1856\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_null_slice(indexer[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m   1857\u001b[0m     \u001b[38;5;66;03m# We are setting an entire column\u001b[39;00m\n\u001b[0;32m-> 1858\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m   1859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1860\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_array_like(value):\n\u001b[1;32m   1861\u001b[0m     \u001b[38;5;66;03m# GH#42099\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Python-WorkSpace/kaggle/kaggle_hull_tactic_2025/.venv/lib/python3.9/site-packages/pandas/core/frame.py:4322\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4319\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   4320\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4321\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[0;32m-> 4322\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Python-WorkSpace/kaggle/kaggle_hull_tactic_2025/.venv/lib/python3.9/site-packages/pandas/core/frame.py:4535\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4526\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4527\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   4528\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4533\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[1;32m   4534\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4535\u001b[0m     value, refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4537\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   4538\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m   4539\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   4540\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype)\n\u001b[1;32m   4541\u001b[0m     ):\n\u001b[1;32m   4542\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   4543\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[0;32m~/Documents/Python-WorkSpace/kaggle/kaggle_hull_tactic_2025/.venv/lib/python3.9/site-packages/pandas/core/frame.py:5288\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   5285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m   5287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[0;32m-> 5288\u001b[0m     \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5289\u001b[0m arr \u001b[38;5;241m=\u001b[39m sanitize_array(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   5290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   5291\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(value, Index)\n\u001b[1;32m   5292\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5295\u001b[0m     \u001b[38;5;66;03m# TODO: Remove kludge in sanitize_array for string mode when enforcing\u001b[39;00m\n\u001b[1;32m   5296\u001b[0m     \u001b[38;5;66;03m# this deprecation\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Python-WorkSpace/kaggle/kaggle_hull_tactic_2025/.venv/lib/python3.9/site-packages/pandas/core/common.py:573\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    570\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[0;32m--> 573\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    574\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    575\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    576\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    577\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    578\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (1) does not match length of index (1798)"
     ]
    }
   ],
   "source": [
    "score(y_tests, positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07752f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5239154616240267"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hit_rate(y_tests['market_forward_excess_returns'], [1.0]*len(y_tests))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053a58cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5509977827050998"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hit_rate(y_tests['market_forward_excess_returns'], positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc9ac02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.031636523472569685"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearson_corr(y_tests['market_forward_excess_returns'], means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b0e92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit_rate(y_true, y_pred, *, dropna: bool = True, margin: float = 0.0, count_ties: bool = False) -> float:\n",
    "    \"\"\"\n",
    "    Sign accuracy (hit rate): fraction of times sign(y_pred) == sign(y_true).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true, y_pred : array-like\n",
    "        Equal-length sequences of numbers.\n",
    "    dropna : bool, default True\n",
    "        If True, drop any pair with NaN in either array.\n",
    "        If False and NaNs are present, returns np.nan.\n",
    "    margin : float, default 0.0\n",
    "        Treat predictions with |y_pred| <= margin as 0 (neutral band).\n",
    "    count_ties : bool, default False\n",
    "        If False, exclude any pair where sign is 0 on either side.\n",
    "        If True, include pairs with sign==0 and count them as correct\n",
    "        only when both are 0.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    hit : float\n",
    "        Proportion in [0,1], or np.nan if no eligible pairs.\n",
    "    \"\"\"\n",
    "    a = np.asarray(y_true, dtype=float).flatten()\n",
    "    b = np.asarray(y_pred, dtype=float).flatten()\n",
    "\n",
    "    if a.shape != b.shape:\n",
    "        raise ValueError(\"y_true and y_pred must have the same shape\")\n",
    "\n",
    "    mask = np.isfinite(a) & np.isfinite(b)\n",
    "    if not dropna and not mask.all():\n",
    "        return np.nan\n",
    "    a = a[mask]\n",
    "    b = b[mask]\n",
    "\n",
    "    # Apply neutral band to predictions\n",
    "    if margin > 0:\n",
    "        b = b.copy()\n",
    "        b[np.abs(b) <= margin] = 0.0\n",
    "\n",
    "    s_true = np.sign(a)\n",
    "    s_pred = np.sign(b)\n",
    "\n",
    "    if count_ties:\n",
    "        eligible = np.ones_like(s_true, dtype=bool)\n",
    "    else:\n",
    "        eligible = (s_true != 0) & (s_pred != 0)\n",
    "\n",
    "    if not np.any(eligible):\n",
    "        return np.nan\n",
    "\n",
    "    hits = (s_true[eligible] == s_pred[eligible]).mean()\n",
    "    return float(hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692b653e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_corr(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Pearson correlation coefficient between y_true and y_pred.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true, y_pred : array-like\n",
    "        Equal-length sequences of numbers.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    corr : float\n",
    "        Pearson correlation coefficient in [-1,1], or np.nan if undefined.\n",
    "    \"\"\"\n",
    "    a = np.asarray(y_true, dtype=float).flatten()\n",
    "    b = np.asarray(y_pred, dtype=float).flatten()\n",
    "\n",
    "    if a.shape != b.shape:\n",
    "        raise ValueError(\"y_true and y_pred must have the same shape\")\n",
    "\n",
    "    mask = np.isfinite(a) & np.isfinite(b)\n",
    "    a = a[mask]\n",
    "    b = b[mask]\n",
    "\n",
    "    if len(a) == 0:\n",
    "        return np.nan\n",
    "\n",
    "    corr, _ = pearsonr(a, b)\n",
    "    return float(corr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
