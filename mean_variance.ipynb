{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "d1a42579",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import pearsonr\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # nuke all warnings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "7672568e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "X = data.drop(columns = ['forward_returns', 'market_forward_excess_returns', 'risk_free_rate'])\n",
    "y = data['market_forward_excess_returns']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "f6da5055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_id</th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>D3</th>\n",
       "      <th>D4</th>\n",
       "      <th>D5</th>\n",
       "      <th>D6</th>\n",
       "      <th>D7</th>\n",
       "      <th>D8</th>\n",
       "      <th>D9</th>\n",
       "      <th>...</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8985</th>\n",
       "      <td>8985</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.533730</td>\n",
       "      <td>-0.432282</td>\n",
       "      <td>0.785053</td>\n",
       "      <td>0.469577</td>\n",
       "      <td>0.837963</td>\n",
       "      <td>1.226772</td>\n",
       "      <td>0.822751</td>\n",
       "      <td>-0.707361</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>-0.649616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8986</th>\n",
       "      <td>8986</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.526455</td>\n",
       "      <td>-0.429506</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>0.671958</td>\n",
       "      <td>0.837963</td>\n",
       "      <td>0.785877</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>-0.715692</td>\n",
       "      <td>0.196098</td>\n",
       "      <td>-0.668289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8987</th>\n",
       "      <td>8987</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.433532</td>\n",
       "      <td>-0.425462</td>\n",
       "      <td>0.734127</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.787698</td>\n",
       "      <td>0.834898</td>\n",
       "      <td>0.823413</td>\n",
       "      <td>-0.723949</td>\n",
       "      <td>0.133929</td>\n",
       "      <td>-0.670946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8988</th>\n",
       "      <td>8988</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.394180</td>\n",
       "      <td>-0.385170</td>\n",
       "      <td>0.695106</td>\n",
       "      <td>0.655423</td>\n",
       "      <td>0.783730</td>\n",
       "      <td>0.994026</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>-0.684937</td>\n",
       "      <td>0.101852</td>\n",
       "      <td>-0.646265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8989</th>\n",
       "      <td>8989</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.370040</td>\n",
       "      <td>-0.451308</td>\n",
       "      <td>0.663360</td>\n",
       "      <td>0.066799</td>\n",
       "      <td>0.783730</td>\n",
       "      <td>1.068037</td>\n",
       "      <td>0.879630</td>\n",
       "      <td>-0.764806</td>\n",
       "      <td>0.079034</td>\n",
       "      <td>-0.705662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8990 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      date_id  D1  D2  D3  D4  D5  D6  D7  D8  D9  ...       V12       V13  \\\n",
       "0           0   0   0   0   1   1   0   0   0   1  ...       NaN       NaN   \n",
       "1           1   0   0   0   1   1   0   0   0   1  ...       NaN       NaN   \n",
       "2           2   0   0   0   1   0   0   0   0   1  ...       NaN       NaN   \n",
       "3           3   0   0   0   1   0   0   0   0   0  ...       NaN       NaN   \n",
       "4           4   0   0   0   1   0   0   0   0   0  ...       NaN       NaN   \n",
       "...       ...  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...       ...       ...   \n",
       "8985     8985   0   0   0   0   0   0   0   0   0  ...  0.533730 -0.432282   \n",
       "8986     8986   0   0   0   0   0   0   0   0   0  ...  0.526455 -0.429506   \n",
       "8987     8987   0   0   1   0   0   0   0   0   0  ...  0.433532 -0.425462   \n",
       "8988     8988   0   0   0   0   0   0   0   0   0  ...  0.394180 -0.385170   \n",
       "8989     8989   0   0   0   0   0   0   0   0   0  ...  0.370040 -0.451308   \n",
       "\n",
       "            V2        V3        V4        V5        V6        V7        V8  \\\n",
       "0          NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "1          NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "2          NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "3          NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "4          NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "8985  0.785053  0.469577  0.837963  1.226772  0.822751 -0.707361  0.142857   \n",
       "8986  0.767857  0.671958  0.837963  0.785877  0.805556 -0.715692  0.196098   \n",
       "8987  0.734127  0.481481  0.787698  0.834898  0.823413 -0.723949  0.133929   \n",
       "8988  0.695106  0.655423  0.783730  0.994026  0.851852 -0.684937  0.101852   \n",
       "8989  0.663360  0.066799  0.783730  1.068037  0.879630 -0.764806  0.079034   \n",
       "\n",
       "            V9  \n",
       "0          NaN  \n",
       "1          NaN  \n",
       "2          NaN  \n",
       "3          NaN  \n",
       "4          NaN  \n",
       "...        ...  \n",
       "8985 -0.649616  \n",
       "8986 -0.668289  \n",
       "8987 -0.670946  \n",
       "8988 -0.646265  \n",
       "8989 -0.705662  \n",
       "\n",
       "[8990 rows x 95 columns]"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "35535026",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = X.columns.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "5d85e6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vol_features = [x for x in features if x.startswith('V')]\n",
    "mkt_features = [x for x in features if x.startswith('M') and not x.startswith('MOM')]\n",
    "econ_features = [x for x in features if x.startswith('E')]\n",
    "interest_features = [x for x in features if x.startswith('I')]\n",
    "price_features = [x for x in features if x.startswith('P')]\n",
    "sentiment_features = [x for x in features if x.startswith('S')]\n",
    "binary_features = [x for x in features if x.startswith('D')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "ff0e3185",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_types = {\n",
    "    'volatility': vol_features,\n",
    "    'market': mkt_features,\n",
    "    'economic': econ_features,\n",
    "    'interest': interest_features,\n",
    "    'price': price_features,\n",
    "    'sentiment': sentiment_features,\n",
    "    'binary': binary_features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "0fbd79c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "46ab0feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features_train = X_train[-252:]\n",
    "y_features_train = y_train[-252:]\n",
    "X_train = X_train[:-252]\n",
    "y_train = y_train[:-252]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "b1031c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cleaned = X_train.ffill().bfill()\n",
    "X_features_train_cleaned = X_features_train.ffill().bfill()\n",
    "X_val_cleaned = X_val.ffill().bfill()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "a335b21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_with_na_train = X_train_cleaned.columns[X_train_cleaned.isna().any()]\n",
    "cols_with_na_val = X_val_cleaned.columns[X_val_cleaned.isna().any()]\n",
    "cols_with_na_features_train = X_features_train_cleaned.columns[X_features_train_cleaned.isna().any()]\n",
    "all_cols_with_na = set(cols_with_na_train).union(set(cols_with_na_val)).union(set(cols_with_na_features_train))\n",
    "drop_cols = list(all_cols_with_na)\n",
    "X_train_cleaned = X_train_cleaned.drop(columns=drop_cols)\n",
    "X_val_cleaned = X_val_cleaned.drop(columns=drop_cols)\n",
    "X_features_train_cleaned = X_features_train_cleaned.drop(columns=drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "9ba852e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(X_tr, y_tr, X_va, y_va, *, k=30, top_corr=60,\n",
    "                     use_extratrees=True, val_last=252, n_repeats=5, seed=42, w_corr=0.6, w_perm=0.4):\n",
    "    # 1) keep a small validation slice\n",
    "    if val_last is not None and len(X_va) > val_last:\n",
    "        Xv = X_va.iloc[-val_last:].astype(np.float32).copy()\n",
    "        yv = y_va.iloc[-val_last:].to_numpy()\n",
    "    else:\n",
    "        Xv = X_va.astype(np.float32).copy()\n",
    "        yv = y_va.to_numpy()\n",
    "\n",
    "    # 2) univariate Pearson on TRAIN; take top N\n",
    "    corr_abs = X_tr.apply(lambda c: np.corrcoef(c, y_tr)[0,1], axis=0).abs().fillna(0.0)\n",
    "    cand = corr_abs.sort_values(ascending=False).head(min(top_corr, X_tr.shape[1])).index.tolist()\n",
    "\n",
    "    # 3) small, fast tree on TRAIN\n",
    "    Tree = ExtraTreesRegressor if use_extratrees else RandomForestRegressor\n",
    "    tree = Tree(\n",
    "        n_estimators=100, max_depth=8, min_samples_leaf=0.01, max_features=0.7,\n",
    "        n_jobs=-1, random_state=seed\n",
    "    ).fit(X_tr[cand].astype(np.float32), y_tr.to_numpy())\n",
    "\n",
    "    # 4) permutation importance on VALID (few repeats, parallel)\n",
    "    pi = permutation_importance(tree, Xv[cand], yv, n_repeats=n_repeats,\n",
    "                                random_state=seed, scoring=\"neg_mean_squared_error\", n_jobs=-1)\n",
    "    perm = pd.Series(np.clip(pi.importances_mean, 0, None), index=cand)\n",
    "\n",
    "    # 5) combine by rank (robust to scaling)\n",
    "    r_corr = corr_abs.loc[cand].rank(ascending=False)\n",
    "    r_perm = perm.rank(ascending=False)\n",
    "    score = (w_corr * r_corr + w_perm * r_perm).sort_values(ascending=False)\n",
    "\n",
    "    selected = score.index[:min(k, len(score))].tolist()\n",
    "    summary = pd.DataFrame({\"corr_abs\": corr_abs.loc[cand], \"perm\": perm, \"score_rank\": score}).loc[score.index]\n",
    "    return selected, summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "919c539c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit_rate(y_true, y_pred, *, dropna: bool = True, margin: float = 0.0, count_ties: bool = False) -> float:\n",
    "    \"\"\"\n",
    "    Sign accuracy (hit rate): fraction of times sign(y_pred) == sign(y_true).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true, y_pred : array-like\n",
    "        Equal-length sequences of numbers.\n",
    "    dropna : bool, default True\n",
    "        If True, drop any pair with NaN in either array.\n",
    "        If False and NaNs are present, returns np.nan.\n",
    "    margin : float, default 0.0\n",
    "        Treat predictions with |y_pred| <= margin as 0 (neutral band).\n",
    "    count_ties : bool, default False\n",
    "        If False, exclude any pair where sign is 0 on either side.\n",
    "        If True, include pairs with sign==0 and count them as correct\n",
    "        only when both are 0.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    hit : float\n",
    "        Proportion in [0,1], or np.nan if no eligible pairs.\n",
    "    \"\"\"\n",
    "    a = np.asarray(y_true, dtype=float)\n",
    "    b = np.asarray(y_pred, dtype=float)\n",
    "\n",
    "    if a.shape != b.shape:\n",
    "        raise ValueError(\"y_true and y_pred must have the same shape\")\n",
    "\n",
    "    mask = np.isfinite(a) & np.isfinite(b)\n",
    "    if not dropna and not mask.all():\n",
    "        return np.nan\n",
    "    a = a[mask]\n",
    "    b = b[mask]\n",
    "\n",
    "    # Apply neutral band to predictions\n",
    "    if margin > 0:\n",
    "        b = b.copy()\n",
    "        b[np.abs(b) <= margin] = 0.0\n",
    "\n",
    "    s_true = np.sign(a)\n",
    "    s_pred = np.sign(b)\n",
    "\n",
    "    if count_ties:\n",
    "        eligible = np.ones_like(s_true, dtype=bool)\n",
    "    else:\n",
    "        eligible = (s_true != 0) & (s_pred != 0)\n",
    "\n",
    "    if not np.any(eligible):\n",
    "        return np.nan\n",
    "\n",
    "    hits = (s_true[eligible] == s_pred[eligible]).mean()\n",
    "    return float(hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "7b2d7639",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_corr(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Pearson correlation coefficient between y_true and y_pred.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true, y_pred : array-like\n",
    "        Equal-length sequences of numbers.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    corr : float\n",
    "        Pearson correlation coefficient in [-1,1], or np.nan if undefined.\n",
    "    \"\"\"\n",
    "    a = np.asarray(y_true, dtype=float)\n",
    "    b = np.asarray(y_pred, dtype=float)\n",
    "\n",
    "    if a.shape != b.shape:\n",
    "        raise ValueError(\"y_true and y_pred must have the same shape\")\n",
    "\n",
    "    mask = np.isfinite(a) & np.isfinite(b)\n",
    "    a = a[mask]\n",
    "    b = b[mask]\n",
    "\n",
    "    if len(a) == 0:\n",
    "        return np.nan\n",
    "\n",
    "    corr, _ = pearsonr(a, b)\n",
    "    return float(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "2dd66682",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_train(X_train, y_train, features = None, alpha=1.0):\n",
    "    \"\"\"\n",
    "    Train a Ridge regression model and evaluate on validation set.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train : pd.DataFrame\n",
    "        Training features.\n",
    "    y_train : pd.Series\n",
    "        Training target.\n",
    "   \n",
    "    alpha : float, default 1.0\n",
    "        Regularization strength for Ridge regression.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model : Ridge\n",
    "        Trained Ridge regression model.\n",
    "    \n",
    "    \"\"\"\n",
    "    model = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('ridge', Ridge(alpha=alpha))\n",
    "    ])\n",
    "\n",
    "    if features:\n",
    "        model.fit(X_train[features], y_train)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "a2f0253d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_train(X_train, y_train, features = None, C=1.0):\n",
    "    \"\"\"\n",
    "    Train a Logistic regression model and evaluate on validation set.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train : pd.DataFrame\n",
    "        Training features.\n",
    "    y_train : pd.Series\n",
    "        Training target.\n",
    "   \n",
    "    C : float, default 1.0\n",
    "        Inverse of regularization strength for Logistic regression.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model : LogisticRegression\n",
    "        Trained Logistic regression model.\n",
    "    \n",
    "    \"\"\"\n",
    "    model = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('logistic', LogisticRegression(C=C, max_iter=1000))\n",
    "    ])\n",
    "\n",
    "    if features:\n",
    "        model.fit(X_train[features], y_train)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "834c8dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trees_train(X_train, y_train, features = None, type='RandomForest'):\n",
    "    \"\"\"\n",
    "    Train a Tree Regressor and evaluate on validation set.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train : pd.DataFrame\n",
    "        Training features.\n",
    "    y_train : pd.Series\n",
    "        Training target.\n",
    "   \n",
    "    n_estimators : int, default 100\n",
    "        Number of trees in the forest.\n",
    "    \n",
    "    max_depth : int or None, default None\n",
    "        Maximum depth of the tree.\n",
    "\n",
    "    random_state : int, default 42\n",
    "        Random seed for reproducibility.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model : Regressor\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if type == 'RandomForest':\n",
    "        model = RandomForestRegressor(n_estimators=100,\n",
    "            max_depth=8,\n",
    "            min_samples_leaf=0.01,     # 1% of samples per leaf (robust)\n",
    "            min_samples_split=0.02,\n",
    "            max_features=0.7,\n",
    "            bootstrap=True,\n",
    "            n_jobs=-1, random_state=42)\n",
    "        \n",
    "    elif type == 'ExtraTrees':\n",
    "        model = ExtraTreesRegressor(\n",
    "            n_estimators=100,\n",
    "            max_depth=8,\n",
    "            min_samples_leaf=0.01,\n",
    "            min_samples_split=0.02,\n",
    "            max_features=0.7,\n",
    "            bootstrap=False,\n",
    "            n_jobs=-1, random_state=42\n",
    "        )\n",
    "\n",
    "    elif type == 'XGBoost':\n",
    "        model = XGBRegressor(\n",
    "            n_estimators=100,\n",
    "            learning_rate=0.10,\n",
    "            max_depth=4,\n",
    "            subsample=0.7,\n",
    "            colsample_bytree=0.7,\n",
    "            min_child_weight=10,       # combats noise\n",
    "            reg_lambda=2.0,\n",
    "            objective=\"reg:squarederror\",\n",
    "            n_jobs=-1, random_state=42\n",
    "        )\n",
    "    elif type == 'LightGBM':\n",
    "        model = LGBMRegressor(\n",
    "            verbosity = -1,\n",
    "            n_estimators=100,\n",
    "            learning_rate=0.10,\n",
    "            max_depth=6,\n",
    "            num_leaves=31,             # <= 2^max_depth for safety\n",
    "            min_data_in_leaf=100,      # robust on small-signal data\n",
    "            feature_fraction=0.7,\n",
    "            bagging_fraction=0.7,\n",
    "            bagging_freq=1,\n",
    "            lambda_l2=5.0,\n",
    "            extra_trees=True,          # adds randomness like ExtraTrees\n",
    "            n_jobs=-1, random_state=42\n",
    "        )\n",
    "    if features:\n",
    "        model.fit(X_train[features], y_train)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "a992ea35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_calibrate(pred_train, y_train, *, dropna: bool = True, fit_intercept: bool = True):\n",
    "    \"\"\"\n",
    "    Fit a scikit-learn LinearRegression on TRAIN predictions:\n",
    "        y = alpha + beta * pred\n",
    "\n",
    "    Returns a Pipeline that reshapes 1D inputs and applies the fitted LinearRegression.\n",
    "    You can call .predict(...) on it with a 1D array/list/Series of predictions.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pred_train : array-like, shape (n_samples,)\n",
    "        Model predictions on the training window (e.g., your tree's outputs).\n",
    "    y_train : array-like, shape (n_samples,)\n",
    "        Realized targets on the training window (e.g., next-day returns).\n",
    "    dropna : bool, default True\n",
    "        Drop pairs with NaN/Inf before fitting. If False and NaNs exist, raises ValueError.\n",
    "    fit_intercept : bool, default True\n",
    "        Passed to LinearRegression.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model : sklearn Pipeline\n",
    "        Use model.predict(new_pred) to get calibrated predictions.\n",
    "        Access alpha/beta via:\n",
    "            alpha = model.named_steps['lr'].intercept_\n",
    "            beta  = model.named_steps['lr'].coef_[0]\n",
    "    \"\"\"\n",
    "    x = np.asarray(pred_train, dtype=float)\n",
    "    y = np.asarray(y_train, dtype=float)\n",
    "    if x.shape != y.shape:\n",
    "        raise ValueError(\"pred_train and y_train must have the same shape\")\n",
    "\n",
    "    mask = np.isfinite(x) & np.isfinite(y)\n",
    "    if not dropna and not mask.all():\n",
    "        raise ValueError(\"NaNs/Infs present; set dropna=True to filter them out.\")\n",
    "    x, y = x[mask], y[mask]\n",
    "    if x.size < 2:\n",
    "        raise ValueError(\"Not enough data to calibrate (need ≥2 finite pairs).\")\n",
    "\n",
    "    # Pipeline so you can pass 1D arrays to .predict() without manual reshape\n",
    "    model = Pipeline(steps=[\n",
    "        (\"reshape\", FunctionTransformer(lambda z: np.asarray(z, dtype=float).reshape(-1, 1), validate=False)),\n",
    "        (\"lr\", LinearRegression(fit_intercept=fit_intercept)),\n",
    "    ])\n",
    "    model.fit(x, y)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "0e6ffbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, X, calibrate_model):\n",
    "    \"\"\"\n",
    "    Generate predictions using the trained model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : Trained model\n",
    "        The trained regression model.\n",
    "    X : pd.DataFrame\n",
    "        Features for prediction.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    y_pred : np.ndarray\n",
    "        Predicted values.\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X)\n",
    "\n",
    "    calibrated_pred = calibrate_model.predict(y_pred)\n",
    "    return calibrated_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "49e0a3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_selected, feature_summary = feature_selection(X_train_cleaned, y_train, X_features_train_cleaned, y_features_train, w_corr=0.9, w_perm=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "e4114e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Hit Rate: 0.5205784204671857 Pearson Correlation: 0.0075661210040566355\n"
     ]
    }
   ],
   "source": [
    "ridge = ridge_train(X_train_cleaned, y_train, alpha=1.0)\n",
    "ridge_predict_train = ridge.predict(X_train_cleaned)\n",
    "calibrate_model = linear_calibrate(ridge_predict_train, y_train)\n",
    "ridge_predict_val = predict(ridge, X_val_cleaned, calibrate_model)\n",
    "ridge_hit_rate = hit_rate(y_val, ridge_predict_val)\n",
    "ridge_pearson = pearson_corr(y_val, ridge_predict_val)\n",
    "print(\"Ridge Hit Rate:\", ridge_hit_rate, \"Pearson Correlation:\", ridge_pearson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f89d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Hit Rate: 0.4860956618464961 Pearson Correlation: -0.010489447890083457\n"
     ]
    }
   ],
   "source": [
    "logistic = logistic_train(X_train_cleaned, y_train.apply(lambda x: 1 if x > 0 else 0), C=1.0)\n",
    "logistic_predict_train = logistic.predict_proba(X_train_cleaned)\n",
    "logistic_calibrate_model = linear_calibrate(logistic_predict_train[:,1], y_train)\n",
    "logistic_predict_val = predict(logistic, X_val_cleaned, logistic_calibrate_model)\n",
    "logistic_hit_rate = hit_rate(y_val, logistic_predict_val)\n",
    "logistic_pearson = pearson_corr(y_val, logistic_predict_val)\n",
    "print(\"Logistic Hit Rate:\", logistic_hit_rate, \"Pearson Correlation:\", logistic_pearson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "ff164609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Hit Rate: 0.5005561735261401 Pearson Correlation: 0.010728478686426124\n"
     ]
    }
   ],
   "source": [
    "lightgbm = trees_train(X_train_cleaned, y_train, features=features_selected, type='LightGBM')\n",
    "lightgbm_predict_train = lightgbm.predict(X_train_cleaned[features_selected])\n",
    "lightgbm_calibrate_model = linear_calibrate(lightgbm_predict_train, y_train)\n",
    "lightgbm_predict_val = predict(lightgbm, X_val_cleaned[features_selected], lightgbm_calibrate_model)\n",
    "lightgbm_hit_rate = hit_rate(y_val, lightgbm_predict_val)\n",
    "lightgbm_pearson = pearson_corr(y_val, lightgbm_predict_val)\n",
    "print(\"LightGBM Hit Rate:\", lightgbm_hit_rate, \"Pearson Correlation:\", lightgbm_pearson)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "33f94925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Hit Rate: 0.5072302558398221 Pearson Correlation: 0.0293201629869648\n"
     ]
    }
   ],
   "source": [
    "rf = trees_train(X_train_cleaned, y_train, type='RandomForest')\n",
    "rf_predict_train = rf.predict(X_train_cleaned)\n",
    "rf_calibrate_model = linear_calibrate(rf_predict_train, y_train)        \n",
    "rf_predict_val = predict(rf, X_val_cleaned, rf_calibrate_model)\n",
    "rf_hit_rate = hit_rate(y_val, rf_predict_val)\n",
    "rf_pearson = pearson_corr(y_val, rf_predict_val)\n",
    "print(\"Random Forest Hit Rate:\", rf_hit_rate, \"Pearson Correlation:\", rf_pearson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "d6fea7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['RandomForest', 'ExtraTrees', 'XGBoost', 'LightGBM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "5336f6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge All: Pearson Correlation:  0.0075661210040566355   Hit Rate:  0.5205784204671857\n",
      "Ridge - Feature Type: volatility, Pearson Correlation: 0.0536, Hit Rate: 0.5323\n",
      "Ridge - Feature Type: market, Pearson Correlation: 0.0361, Hit Rate: 0.5050\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['E7'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[309], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRidge All: Pearson Correlation: \u001b[39m\u001b[38;5;124m'\u001b[39m, pearson_score, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m  Hit Rate: \u001b[39m\u001b[38;5;124m'\u001b[39m, hitrate_score)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m feature_types\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m----> 9\u001b[0m     ridge_subset \u001b[38;5;241m=\u001b[39m ridge_train(\u001b[43mX_train_cleaned\u001b[49m\u001b[43m[\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m]\u001b[49m, y_train, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m     10\u001b[0m     ridge_subset_predict_train \u001b[38;5;241m=\u001b[39m ridge_subset\u001b[38;5;241m.\u001b[39mpredict(X_train_cleaned[value])\n\u001b[1;32m     11\u001b[0m     calibrate_model \u001b[38;5;241m=\u001b[39m linear_calibrate(ridge_subset_predict_train, y_train)\n",
      "File \u001b[0;32m~/Documents/Python-WorkSpace/kaggle/kaggle_hull_tactic_2025/.venv/lib/python3.9/site-packages/pandas/core/frame.py:4119\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4118\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4119\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4121\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/Python-WorkSpace/kaggle/kaggle_hull_tactic_2025/.venv/lib/python3.9/site-packages/pandas/core/indexes/base.py:6212\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6209\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6210\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6212\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6214\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6216\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Python-WorkSpace/kaggle/kaggle_hull_tactic_2025/.venv/lib/python3.9/site-packages/pandas/core/indexes/base.py:6264\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6263\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6264\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['E7'] not in index\""
     ]
    }
   ],
   "source": [
    "ridge_all = ridge_train(X_train_cleaned, y_train, list(X_train_cleaned.columns), alpha=1.0)\n",
    "ridge_all_predict_train = ridge_all.predict(X_train_cleaned)\n",
    "calibrate_model = linear_calibrate(ridge_all_predict_train, y_train)\n",
    "y_pred_ridge = predict(ridge_all, X_val_cleaned, calibrate_model)\n",
    "pearson_score = pearson_corr(y_val, y_pred_ridge)\n",
    "hitrate_score = hit_rate(y_val, y_pred_ridge)\n",
    "print('Ridge All: Pearson Correlation: ', pearson_score, '  Hit Rate: ', hitrate_score)\n",
    "for key, value in feature_types.items():\n",
    "    ridge_subset = ridge_train(X_train_cleaned[value], y_train, alpha=1.0)\n",
    "    ridge_subset_predict_train = ridge_subset.predict(X_train_cleaned[value])\n",
    "    calibrate_model = linear_calibrate(ridge_subset_predict_train, y_train)\n",
    "    y_pred_subset = predict(ridge_subset, X_val_cleaned[value], calibrate_model)\n",
    "    pearson_score = pearson_corr(y_val, y_pred_subset)\n",
    "    hitrate_score = hit_rate(y_val, y_pred_subset)\n",
    "    print(f'Ridge - Feature Type: {key}, Pearson Correlation: {pearson_score:.4f}, Hit Rate: {hitrate_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804f6414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest All: Pearson Correlation: 0.0240, Hit Rate: 0.5111\n",
      "RandomForest - Feature Type: volatility, Pearson Correlation: 0.0303, Hit Rate: 0.5245\n",
      "RandomForest - Feature Type: market, Pearson Correlation: 0.0281, Hit Rate: 0.5044\n",
      "RandomForest - Feature Type: economic, Pearson Correlation: -0.0137, Hit Rate: 0.4989\n",
      "RandomForest - Feature Type: interest, Pearson Correlation: 0.0044, Hit Rate: 0.4967\n",
      "RandomForest - Feature Type: price, Pearson Correlation: 0.0355, Hit Rate: 0.4900\n",
      "RandomForest - Feature Type: sentiment, Pearson Correlation: 0.0001, Hit Rate: 0.5195\n",
      "RandomForest - Feature Type: binary, Pearson Correlation: 0.0067, Hit Rate: 0.4967\n",
      "ExtraTrees All: Pearson Correlation: 0.0143, Hit Rate: 0.4967\n",
      "ExtraTrees - Feature Type: volatility, Pearson Correlation: 0.0235, Hit Rate: 0.5239\n",
      "ExtraTrees - Feature Type: market, Pearson Correlation: 0.0239, Hit Rate: 0.5000\n",
      "ExtraTrees - Feature Type: economic, Pearson Correlation: -0.0147, Hit Rate: 0.5095\n",
      "ExtraTrees - Feature Type: interest, Pearson Correlation: 0.0015, Hit Rate: 0.4905\n",
      "ExtraTrees - Feature Type: price, Pearson Correlation: -0.0035, Hit Rate: 0.4900\n",
      "ExtraTrees - Feature Type: sentiment, Pearson Correlation: -0.0022, Hit Rate: 0.5145\n",
      "ExtraTrees - Feature Type: binary, Pearson Correlation: 0.0091, Hit Rate: 0.4972\n",
      "XGBoost All: Pearson Correlation: -0.0088, Hit Rate: 0.4889\n",
      "XGBoost - Feature Type: volatility, Pearson Correlation: -0.0055, Hit Rate: 0.5072\n",
      "XGBoost - Feature Type: market, Pearson Correlation: 0.0671, Hit Rate: 0.4961\n",
      "XGBoost - Feature Type: economic, Pearson Correlation: -0.0091, Hit Rate: 0.5072\n",
      "XGBoost - Feature Type: interest, Pearson Correlation: -0.0417, Hit Rate: 0.4844\n",
      "XGBoost - Feature Type: price, Pearson Correlation: 0.0180, Hit Rate: 0.4917\n",
      "XGBoost - Feature Type: sentiment, Pearson Correlation: -0.0205, Hit Rate: 0.4889\n",
      "XGBoost - Feature Type: binary, Pearson Correlation: 0.0063, Hit Rate: 0.4972\n",
      "LightGBM All: Pearson Correlation: 0.0300, Hit Rate: 0.5089\n",
      "LightGBM - Feature Type: volatility, Pearson Correlation: 0.0306, Hit Rate: 0.5311\n",
      "LightGBM - Feature Type: market, Pearson Correlation: 0.0247, Hit Rate: 0.5033\n",
      "LightGBM - Feature Type: economic, Pearson Correlation: 0.0044, Hit Rate: 0.5117\n",
      "LightGBM - Feature Type: interest, Pearson Correlation: -0.0002, Hit Rate: 0.5078\n",
      "LightGBM - Feature Type: price, Pearson Correlation: 0.0007, Hit Rate: 0.4917\n",
      "LightGBM - Feature Type: sentiment, Pearson Correlation: 0.0063, Hit Rate: 0.5011\n",
      "LightGBM - Feature Type: binary, Pearson Correlation: 0.0076, Hit Rate: 0.4967\n"
     ]
    }
   ],
   "source": [
    "for model_type in models:\n",
    "    tree_all = trees_train(X_train_cleaned, y_train, type=model_type)\n",
    "    tree_all_predict_train = tree_all.predict(X_train_cleaned)\n",
    "    calibrate_model = linear_calibrate(tree_all_predict_train, y_train)\n",
    "    y_pred_tree = predict(tree_all, X_val_cleaned, calibrate_model)\n",
    "    pearson_score = pearson_corr(y_val, y_pred_tree)\n",
    "    hitrate_score = hit_rate(y_val, y_pred_tree)\n",
    "    print(f'{model_type} All: Pearson Correlation: {pearson_score:.4f}, Hit Rate: {hitrate_score:.4f}')\n",
    "    for key, value in feature_types.items():\n",
    "        tree_subset = trees_train(X_train_cleaned[value], y_train, type=model_type)\n",
    "        tree_subset_predict_train = tree_subset.predict(X_train_cleaned[value])\n",
    "        calibrate_model = linear_calibrate(tree_subset_predict_train, y_train)\n",
    "        y_pred_subset = predict(tree_subset, X_val_cleaned[value], calibrate_model)\n",
    "        pearson_score = pearson_corr(y_val, y_pred_subset)\n",
    "        hitrate_score = hit_rate(y_val, y_pred_subset)\n",
    "        print(f'{model_type} - Feature Type: {key}, Pearson Correlation: {pearson_score:.4f}, Hit Rate: {hitrate_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188d28d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7192   -0.004158\n",
       "7193   -0.001529\n",
       "7194    0.001474\n",
       "7195    0.004647\n",
       "7196    0.008136\n",
       "          ...   \n",
       "8985    0.001990\n",
       "8986    0.001845\n",
       "8987    0.002424\n",
       "8988    0.007843\n",
       "8989   -0.000368\n",
       "Name: market_forward_excess_returns, Length: 1798, dtype: float64"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0852208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7194    0.001474\n",
       "7195    0.004647\n",
       "7196    0.008136\n",
       "7200    0.004543\n",
       "7202    0.005060\n",
       "          ...   \n",
       "8983    0.007887\n",
       "8985    0.001990\n",
       "8986    0.001845\n",
       "8987    0.002424\n",
       "8988    0.007843\n",
       "Name: market_forward_excess_returns, Length: 942, dtype: float64"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val[y_val>0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
